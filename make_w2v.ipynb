{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "actual-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "# my lib\n",
    "import textlib as tl\n",
    "import Word2VecModel as wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "latter-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKERS = multiprocessing.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sunset-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input / output file name\n",
    "#corpora_file_name = 'D:/ml/TCL2021_telco_embedding/dataset/telco_corpora.dat'\n",
    "#w2v_model_file_name_prefix = 'D:/ml/TCL2021_telco_embedding/dataset/w2v/telco_w2v_'\n",
    "\n",
    "corpora_file_name = '../../dataset/telco_embedding/corpora/telco_corpora.dat'\n",
    "w2v_model_file_name_prefix = '../../dataset/telco_embedding/w2v/telco_w2v_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chubby-concern",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 여러개의 w2v 모델을 만들기 위한 table\n",
    "MODEL_COUNT = 9\n",
    "W2V_TRAIN_PARAMS = {\n",
    "    'MODEL_NAME': ['V10000_E100_W3_E50','V10000_E100_W5_E50','V10000_E100_W7_E50',\n",
    "                   'V10000_E200_W3_E50','V10000_E200_W5_E50','V10000_E200_W7_E50',\n",
    "                   'V10000_E300_W3_E50','V10000_E300_W5_E50','V10000_E300_W7_E50'],\n",
    "    'MAX_VOCAB_SIZE': [10000] * MODEL_COUNT,\n",
    "    'EMBEDDING_SIZE': [100,100,100,200,200,200,300,300,300],\n",
    "    'WINDOW_SIZE' : [3,5,7,3,5,7,3,5,7],\n",
    "    'EPOCHS': [10] * MODEL_COUNT\n",
    "}\n",
    "\n",
    "# parameter 잘못 넣었는지 검증\n",
    "assert len(W2V_TRAIN_PARAMS['MODEL_NAME']) == MODEL_COUNT\n",
    "assert len(W2V_TRAIN_PARAMS['MAX_VOCAB_SIZE']) == MODEL_COUNT\n",
    "assert len(W2V_TRAIN_PARAMS['EMBEDDING_SIZE']) == MODEL_COUNT\n",
    "assert len(W2V_TRAIN_PARAMS['WINDOW_SIZE']) == MODEL_COUNT\n",
    "assert len(W2V_TRAIN_PARAMS['EPOCHS']) == MODEL_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hidden-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_w2v_model(model_count, params):\n",
    "    for i, (model_name, max_vocab_size, embedding_size, window_size, epochs) in \\\n",
    "            enumerate(zip(params['MODEL_NAME'],\n",
    "                          params['MAX_VOCAB_SIZE'],\n",
    "                          params['EMBEDDING_SIZE'],\n",
    "                          params['WINDOW_SIZE'],\n",
    "                          params['EPOCHS'])):\n",
    "        print(f'---- {i} 시작!! ----')\n",
    "        w2v_model = wv.Word2VecModel()\n",
    "        w2v_model.create(corpora_file_name, \n",
    "                           w2v_model_file_name_prefix + model_name, \n",
    "                           max_vocab_size=max_vocab_size, \n",
    "                           embedding_size=embedding_size,\n",
    "                           epochs=epochs,\n",
    "                           window=window_size,\n",
    "                           workers=WORKERS)    \n",
    "        \n",
    "        if i + 1 >= model_count:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "heard-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 시작!! ----\n",
      "10000개의 단어 내에서 최소 빈도수는 45입니다.\n",
      "Epoch: 1\tLoss after epoch 1: 22115754.0\n",
      "Epoch: 2\tLoss after epoch 2: 15975354.0\n",
      "Epoch: 3\tLoss after epoch 3: 11487016.0\n",
      "Epoch: 4\tLoss after epoch 4: 11470444.0\n",
      "Epoch: 5\tLoss after epoch 5: 7052928.0\n",
      "Epoch: 6\tLoss after epoch 6: 1959896.0\n",
      "Epoch: 7\tLoss after epoch 7: 1940496.0\n",
      "Epoch: 8\tLoss after epoch 8: 1902128.0\n",
      "Epoch: 9\tLoss after epoch 9: 1801008.0\n",
      "Epoch: 10\tLoss after epoch 10: 1789888.0\n"
     ]
    }
   ],
   "source": [
    "# 테스트로 하나만 만들자.\n",
    "model_create_count = 1\n",
    "create_multi_w2v_model(model_create_count, W2V_TRAIN_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sunset-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10031\n",
      "10031\n",
      "10031\n",
      "채널\n",
      "87\n",
      "[-1.28704607  0.60899276  1.52758682  0.14216805 -0.03208986 -0.35162911\n",
      " -0.23014656 -0.54449201 -0.13295713  0.05977995  0.17421292 -0.23925877\n",
      " -0.02696096 -0.27940512 -0.1087674  -0.1742404   0.71315104 -0.15916385\n",
      "  0.44866425 -0.93803859  0.28822842  0.04694553  0.49181566 -0.73227102\n",
      " -0.58628809 -0.53829026 -0.9319514   0.00437926 -0.07131036  0.97412002\n",
      " -0.44056585  0.72468114  0.1171393  -0.00634099 -0.24705975  1.00534046\n",
      " -0.93818158  0.72065139 -0.1647618   0.42863211  0.34628803 -0.70248997\n",
      "  0.08718582 -0.41112477  0.36475015  0.17013627 -0.0905133  -0.45467418\n",
      "  0.05980843 -0.40604788  0.37260205 -0.90084326 -0.51738024 -0.08958094\n",
      " -0.16105573  0.55400401  0.58894467  0.00735143  0.2127317   1.16864502\n",
      "  0.02616288  1.17424631 -0.21616504 -0.17483246 -0.95434606 -0.55734736\n",
      " -0.5193339  -0.21042204 -0.57819569 -0.49153396 -0.16887598  0.92017525\n",
      "  1.06740928 -0.67761111  0.32668903  0.08866875 -0.02258844 -0.58247453\n",
      "  0.61903286 -0.10279644  0.65453357  0.74717975  0.7348184  -0.02496701\n",
      " -0.40502757  0.36644122 -0.27532256  0.19275323  0.530563   -0.59632313\n",
      "  0.43930945  0.29128626  0.79550833  0.47181696  0.04196488  0.4115262\n",
      "  1.09213424 -0.08273675 -0.85047686  0.7902565 ]\n",
      "[-0.22966681  0.10867165  0.27259008  0.02536916 -0.00572627 -0.06274642\n",
      " -0.04106848 -0.09716182 -0.02372552  0.01066743  0.03108741 -0.04269451\n",
      " -0.00481105 -0.04985842 -0.01940899 -0.03109231  0.12725817 -0.02840198\n",
      "  0.08006185 -0.16738821  0.05143289  0.00837719  0.087762   -0.13067003\n",
      " -0.10462012 -0.09605515 -0.16630198  0.00078146 -0.01272497  0.17382675\n",
      " -0.07861673  0.12931566  0.02090291 -0.00113152 -0.04408655  0.17939788\n",
      " -0.16741372  0.12859657 -0.0294009   0.07648722  0.06179333 -0.12535576\n",
      "  0.01555787 -0.07336312  0.0650878   0.03035995 -0.01615164 -0.08113429\n",
      "  0.01067251 -0.07245717  0.06648894 -0.16075089 -0.09232387 -0.01598526\n",
      " -0.02873957  0.09885919  0.10509418  0.00131182  0.03796089  0.20853875\n",
      "  0.00466863  0.20953827 -0.03857355 -0.03119796 -0.17029819 -0.0994558\n",
      " -0.09267249 -0.03754874 -0.10317607 -0.08771173 -0.03013506  0.16420058\n",
      "  0.19047375 -0.12091625  0.05829599  0.01582249 -0.00403079 -0.10393961\n",
      "  0.11046326 -0.0183435   0.11679818  0.13333042  0.1311246  -0.00445524\n",
      " -0.07227511  0.06538957 -0.04912991  0.03439583  0.09467626 -0.10641082\n",
      "  0.07839253  0.05197855  0.14195441  0.08419333  0.00748842  0.07343475\n",
      "  0.19488579 -0.01476395 -0.15176326  0.14101725]\n"
     ]
    }
   ],
   "source": [
    "# 테스트로 0번째 모델 한번 가져와보자.\n",
    "i = 0\n",
    "w2v_model = wv.Word2VecModel()\n",
    "w2v_model.load(w2v_model_file_name_prefix + W2V_TRAIN_PARAMS['MODEL_NAME'][i])\n",
    "\n",
    "print( len(w2v_model.index2word) )\n",
    "print( len(w2v_model.word2index) )\n",
    "print( len(w2v_model.weight) )\n",
    "\n",
    "print( w2v_model.index2word[200] )\n",
    "print( w2v_model.word2index['약정'] )\n",
    "print( w2v_model.weight[2583] )\n",
    "print( w2v_model.norm_weight[2583] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36] *",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
