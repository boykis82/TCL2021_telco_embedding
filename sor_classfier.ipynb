{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polish-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eunjeon import Mecab\n",
    "import eunjeon\n",
    "import konlpy\n",
    "\n",
    "# numpy & pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# scikit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Layer, Dense, Embedding, Activation, LSTM, Bidirectional, GRU, Softmax, Dropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# my lib\n",
    "import textlib as tl\n",
    "import Word2VecModel as wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuck-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_file_name_prefix = f'D:/dataset/w2v/telco_w2v_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "novel-visitor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 여러개의 w2v 모델을 만들기 위한 table\n",
    "MODEL_COUNT = 9\n",
    "W2V_TRAIN_PARAMS = {\n",
    "    'MODEL_NAME': ['V10000_E100_W3_E50','V10000_E100_W5_E50','V10000_E100_W7_E50',\n",
    "                   'V10000_E200_W3_E50','V10000_E200_W5_E50','V10000_E200_W7_E50',\n",
    "                   'V10000_E300_W3_E50','V10000_E300_W5_E50','V10000_E300_W7_E50'],\n",
    "    'MAX_VOCAB_SIZE': [10000] * MODEL_COUNT,\n",
    "    'EMBEDDING_SIZE': [100,100,100,200,200,200,300,300,300],\n",
    "    'WINDOW_SIZE' : [3,5,7,3,5,7,3,5,7],\n",
    "    'EPOCHS': [40] * MODEL_COUNT\n",
    "}\n",
    "\n",
    "# parameter 잘못 넣었는지 검증\n",
    "assert len(W2V_TRAIN_PARAMS['MODEL_NAME']) == MODEL_COUNT\n",
    "assert len(W2V_TRAIN_PARAMS['MAX_VOCAB_SIZE']) == MODEL_COUNT\n",
    "assert len(W2V_TRAIN_PARAMS['EMBEDDING_SIZE']) == MODEL_COUNT\n",
    "assert len(W2V_TRAIN_PARAMS['WINDOW_SIZE']) == MODEL_COUNT\n",
    "assert len(W2V_TRAIN_PARAMS['EPOCHS']) == MODEL_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-affiliate",
   "metadata": {},
   "source": [
    "# 여기까지 word2vec 모델 만들어서 파일 쓰는 것까지!!!(upstream task)\n",
    "# 이 밑에서부터는 SOR 을 분류하는 downstream task!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "human-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy plot\n",
    "def plot_hist(hist):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, axes = plt.subplots(1,2)\n",
    "    loss_ax = axes[0]\n",
    "    acc_ax = axes[1]\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper right')\n",
    "\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "    acc_ax.set_ylabel('accuracy')\n",
    "    acc_ax.legend(loc='lower right')\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "possible-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105268, 5)\n"
     ]
    }
   ],
   "source": [
    "# sor dataset 읽어옴\n",
    "input_file_name = 'D:/dataset/sor_dataset.xlsx'\n",
    "try:\n",
    "    df = pd.read_excel(input_file_name, sheet_name=0, engine='openpyxl')\n",
    "except FileNotFoundError:\n",
    "    print(f'{input_file_name}이 없습니다! skip!')\n",
    "\n",
    "print( df.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "successful-judge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92483, 5)\n"
     ]
    }
   ],
   "source": [
    "# null 인 row가 하나라도 있으면 삭제\n",
    "df.dropna(axis=0, inplace=True)\n",
    "print( df.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "victorian-object",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92197, 5)\n"
     ]
    }
   ],
   "source": [
    "# co(요청회사)가 SKT, SKB인 것만 추출. 너무 적은 표본도 삭제\n",
    "df = df[ ((df['co'] == 'SKT') | (df['co'] == 'SKB')) & \\\n",
    "             (\n",
    "                (df['label'] != 'Configuration') & \n",
    "                (df['label'] != 'EAI/EIGW') &\n",
    "                (df['label'] != 'I/F 유틸') &\n",
    "                (df['label'] != 'MTOKTOK') &\n",
    "                (df['label'] != 'PPS 상품권') &\n",
    "                (df['label'] != 'Utility') &\n",
    "                (df['label'] != '고객상담') &\n",
    "                (df['label'] != '접근 관리') &\n",
    "                (df['label'] != '코드 관리')\n",
    "             )\n",
    "       ]\n",
    "\n",
    "print( df.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "buried-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "3522\n",
      "384.6967471826632\n"
     ]
    }
   ],
   "source": [
    "# dataset의 문장 길이 통계\n",
    "def avg(it):\n",
    "    return sum(it) / len(it)\n",
    "\n",
    "lens = [len(s) for s in df['sentence'].values]\n",
    "#lens = [len(s) for s in X]\n",
    "\n",
    "print( min(lens) )\n",
    "print( max(lens) )\n",
    "print( avg(lens) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "naval-deficit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req_ym</th>\n",
       "      <th>co</th>\n",
       "      <th>req_br</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Billing/OSS</th>\n",
       "      <td>6699</td>\n",
       "      <td>6699</td>\n",
       "      <td>6699</td>\n",
       "      <td>6699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>6484</td>\n",
       "      <td>6484</td>\n",
       "      <td>6484</td>\n",
       "      <td>6484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRM</th>\n",
       "      <td>24176</td>\n",
       "      <td>24176</td>\n",
       "      <td>24176</td>\n",
       "      <td>24176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTC</th>\n",
       "      <td>1676</td>\n",
       "      <td>1676</td>\n",
       "      <td>1676</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer Care</th>\n",
       "      <td>11064</td>\n",
       "      <td>11064</td>\n",
       "      <td>11064</td>\n",
       "      <td>11064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERP</th>\n",
       "      <td>5661</td>\n",
       "      <td>5661</td>\n",
       "      <td>5661</td>\n",
       "      <td>5661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCEAN</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSS</th>\n",
       "      <td>5458</td>\n",
       "      <td>5458</td>\n",
       "      <td>5458</td>\n",
       "      <td>5458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRM</th>\n",
       "      <td>2597</td>\n",
       "      <td>2597</td>\n",
       "      <td>2597</td>\n",
       "      <td>2597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TWORLD</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bizservice</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>경영정보/IT관리</th>\n",
       "      <td>489</td>\n",
       "      <td>489</td>\n",
       "      <td>489</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공통</th>\n",
       "      <td>1308</td>\n",
       "      <td>1308</td>\n",
       "      <td>1308</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공통자원관리</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>그룹포탈</th>\n",
       "      <td>3764</td>\n",
       "      <td>3764</td>\n",
       "      <td>3764</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기타</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013</td>\n",
       "      <td>10013</td>\n",
       "      <td>10013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>무선OSS</th>\n",
       "      <td>1941</td>\n",
       "      <td>1941</td>\n",
       "      <td>1941</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미납</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>빌링</th>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>상품 및 오퍼 관리</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수납관리</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>스마트플래너</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>연동</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업기타</th>\n",
       "      <td>5672</td>\n",
       "      <td>5672</td>\n",
       "      <td>5672</td>\n",
       "      <td>5672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>오더관리</th>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인터페이스</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인트라넷</th>\n",
       "      <td>741</td>\n",
       "      <td>741</td>\n",
       "      <td>741</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자동납부</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자원관리</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>재무/정산</th>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>청구관리</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>통계</th>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               req_ym     co  req_br  sentence\n",
       "label                                         \n",
       "Billing/OSS      6699   6699    6699      6699\n",
       "CC               6484   6484    6484      6484\n",
       "CRM             24176  24176   24176     24176\n",
       "CTC              1676   1676    1676      1676\n",
       "Customer Care   11064  11064   11064     11064\n",
       "ERP              5661   5661    5661      5661\n",
       "OCEAN              35     35      35        35\n",
       "OSS              5458   5458    5458      5458\n",
       "PRM              2597   2597    2597      2597\n",
       "TWORLD             83     83      83        83\n",
       "bizservice        145    145     145       145\n",
       "경영정보/IT관리         489    489     489       489\n",
       "공통               1308   1308    1308      1308\n",
       "공통자원관리             12     12      12        12\n",
       "그룹포탈             3764   3764    3764      3764\n",
       "기타              10013  10013   10013     10013\n",
       "무선OSS            1941   1941    1941      1941\n",
       "미납                 39     39      39        39\n",
       "빌링               2589   2589    2589      2589\n",
       "상품 및 오퍼 관리         43     43      43        43\n",
       "수납관리               99     99      99        99\n",
       "스마트플래너             17     17      17        17\n",
       "연동                545    545     545       545\n",
       "영업기타             5672   5672    5672      5672\n",
       "오더관리              258    258     258       258\n",
       "인터페이스             116    116     116       116\n",
       "인트라넷              741    741     741       741\n",
       "자동납부               32     32      32        32\n",
       "자원관리               86     86      86        86\n",
       "재무/정산              81     81      81        81\n",
       "청구관리               56     56      56        56\n",
       "통계                218    218     218       218"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 통계\n",
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tamil-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 모델은 sentence와 label만 써보자\n",
    "# df_zip = df[ ['sentence', 'label'] ]\n",
    "\n",
    "y = df.pop('label')\n",
    "X = df.pop('sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boolean-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열로 되어 있는 label을 categorical value로 변환\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "different-contract",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  8  8  8  4  3  1 15 18 15  4  2 15 15 15 15  4 15 23  8]\n",
      "['PRM' 'PRM' 'PRM' 'PRM' 'Customer Care' 'CTC' 'CC' '기타' '빌링' '기타'\n",
      " 'Customer Care' 'CRM' '기타' '기타' '기타' '기타' 'Customer Care' '기타' '영업기타'\n",
      " 'PRM']\n"
     ]
    }
   ],
   "source": [
    "# 잘 변환됐나?\n",
    "print( y[0:20] )\n",
    "print( label_encoder.inverse_transform(y[0:20]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-welsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "earlier-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = wv.Word2VecModel()\n",
    "w2v_model.load(w2v_model_file_name_prefix + W2V_TRAIN_PARAMS['MODEL_NAME'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "periodic-company",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- raw sentence ---\n",
      "소속영업장 변경 요청(SKB사내유치본점 -＞ 엘에스통신-채널고객팀) . SR-1705-0886;- 해당 서비스번호로 개통이 됐다고 하는데 스윙에서 서비스 번호로 검색이 되지 않아서 ;변경이 어렵습니다.;- 유통지원센터에서 청약 등록 시, 창리정보통신으로 등록했으나 스윙 이관후 확인 시 소속영업장이 금란텔레콤으로 되어 있어 변경 요청 함 . 요청유형:자료수정,요청유형상세:PRM,검토/승인자성명:홍도희,검토/승인자사번:1700,검토승인자기간:2017-05-31,요청내용:1. 변경 전 유통망 : SKB사내유치본점2. 변경 후 유통망 : 엘에스통신(E00901)3. 서비스번호 : 7276564018 또는 1670-84914. 고객 : 세종화재해상자동차손해사정(주)5. 담당 AM : 박성M6. 적용 시점 : 6월 지급 분부터 적용(5월 영업에 대한)\n",
      "\n",
      "--- 클렌징된 sentence ---\n",
      "소속영업장 변경 요청 SKB사내유치본점 엘에스통신 채널고객팀 . SR 해당 서비스번호로 개통이 됐다고 하는데 스윙에서 서비스 번호로 검색이 되지 않아서 변경이 어렵습니다. 유통지원센터에서 청약 등록 시 창리정보통신으로 등록했으나 스윙 이관후 확인 시 소속영업장이 금란텔레콤으로 되어 있어 변경 요청 함 . 요청유형 자료수정 요청유형상세 PRM 검토/승인자성명 홍도희 검토/승인자사번 검토승인자기간 요청내용 . 변경 전 유통망 SKB사내유치본점 . 변경 후 유통망 엘에스통신 E . 서비스번호 또는 . 고객 세종화재해상자동차손해사정 주 . 담당 AM 박성M . 적용 시점 월 지급 분부터 적용 월 영업에 대한 \n",
      "\n",
      "--- 구두점 단위로 잘라서 배열화 ---\n",
      "['소속영업장 변경 요청 SKB사내유치본점 엘에스통신 채널고객팀', 'SR 해당 서비스번호로 개통이 됐다고 하는데 스윙에서 서비스 번호로 검색이 되지 않아서 변경이 어렵습니다', '유통지원센터에서 청약 등록 시 창리정보통신으로 등록했으나 스윙 이관후 확인 시 소속영업장이 금란텔레콤으로 되어 있어 변경 요청 함', '요청유형 자료수정 요청유형상세 PRM 검토/승인자성명 홍도희 검토/승인자사번 검토승인자기간 요청내용', '변경 전 유통망 SKB사내유치본점', '변경 후 유통망 엘에스통신 E', '서비스번호 또는', '고객 세종화재해상자동차손해사정 주', '담당 AM 박성M', '적용 시점 월 지급 분부터 적용 월 영업에 대한']\n",
      "\n",
      "--- 형태소 ---\n",
      "['소속', '영업장', 'SKB', '사내', '유치', '본점', '에스', '통신', '채널', '고객', '팀', 'SR', '해당', '서비스', '번호', '개통', '스윙', '서비스', '번호', '검색', '어렵', '유통', '지원', '센터', '청약', '등록', '시', '창리', '정보', '통신', '등록', '스윙', '소속', '영업장', '금란', '텔레콤', '유형', '자료', '수정', '유형', '상세', 'PRM', '검토', '승인', '성명', '홍도', '희', '검토', '승인', '사', '번', '검토', '승인', '자기', '내용', '전', '유통망', 'SKB', '사내', '유치', '본점', '후', '유통망', '에스', '통신', 'E', '서비스', '번호', '고객', '세종', '해상', '자동차', '손해', '사정', '주', '담당', 'AM', '박성', 'M', '적용', '시점', '월', '지급', '적용', '월', '영업']\n",
      "\n",
      "word id\n",
      "[356, 381, 240, 485, 675, 1117, 1079, 274, 200, 5, 123, 1410, 46, 11, 6, 85, 222, 11, 6, 495, 2070, 913, 215, 100, 245, 23, 13, 10084, 10, 274, 23, 222, 356, 381, 10084, 657, 7, 81, 86, 7, 111, 674, 3, 2, 34, 2742, 1200, 3, 2, 19, 21, 3, 2, 35, 8, 76, 352, 240, 485, 675, 1117, 12, 352, 1079, 274, 367, 11, 6, 5, 2575, 2317, 2261, 2711, 3266, 375, 342, 953, 10084, 150, 126, 423, 22, 282, 126, 22, 310]\n",
      "\n",
      "8\n",
      "['CRM']\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "print('--- raw sentence ---')\n",
    "print( X[0] )\n",
    "print()\n",
    "\n",
    "print('--- 클렌징된 sentence ---')\n",
    "cleansed_text = tl.clean_text( X[0] )\n",
    "print( cleansed_text )\n",
    "print()\n",
    "\n",
    "print('--- 구두점 단위로 잘라서 배열화 ---')\n",
    "tokenized_sentence = tl.segment_sentences(cleansed_text)\n",
    "print( tokenized_sentence )\n",
    "print()\n",
    "\n",
    "print('--- 형태소 ---')\n",
    "# SOR이니까 변경/요청 이란 단어는 항상 들어가므로 삭제\n",
    "ignore_words = ['변경','요청']\n",
    "corpora = ' '.join(tl.get_corpora(tokenized_sentence, ignore_words)).split(' ')\n",
    "print(corpora)\n",
    "print()\n",
    "\n",
    "sequence = w2v_model.get_words_indexes(corpora)\n",
    "print('word id')\n",
    "print(sequence)\n",
    "print()\n",
    "\n",
    "print(y[0])\n",
    "print(label_encoder.inverse_transform([y[100]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "plain-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw 문장을 전처리(쪼개고 형태소로 분리하고 단어id로 바꾸고 padding까지)\n",
    "def preprocess_sentence(X, w2v_model, max_sentence_len=200, ignore_words=None):\n",
    "    # 문장 전처리\n",
    "    preprocessed_X = []\n",
    "    print(f'{len(X)} 개의 데이터 존재 확인!')\n",
    "\n",
    "    for i, text in enumerate(X):\n",
    "        try:\n",
    "            # 클렌징\n",
    "            cleansed_text = tl.clean_text(text)\n",
    "        except TypeError:\n",
    "            print(f'      {i+1} 번째 데이터에 문제가 있어 skip!')\n",
    "            continue\n",
    "\n",
    "        # 문장으로 분리하여 배열로 리턴\n",
    "        sentences = tl.segment_sentences(cleansed_text)\n",
    "        # 문장 배열을 입릭으로 받아 형태소로 쪼갠 뒤, 다시 하나의 문자열로 변환하여 저장\n",
    "        corpora = ' '.join(tl.get_corpora(sentences, ignore_words)).split(' ')\n",
    "        # 단어들을 id로 변환\n",
    "        sequence = w2v_model.get_words_indexes(corpora)\n",
    "        \n",
    "        preprocessed_X.append(sequence)\n",
    "\n",
    "        if i % 5000 == 0 and i > 0:\n",
    "            print(f'      {i} 번째 데이터 처리 완료!')\n",
    "\n",
    "    print('데이터 전체 처리 완료!')\n",
    "    # 최대 길이까지만 문장 사용. 짧은 문장은 뒤쪽에 PADDING token으로 채워서 리턴\n",
    "    preprocessed_X = pad_sequences( preprocessed_X, maxlen=max_sentence_len, padding='post', value=w2v_model.word2index[PAD_TOKEN] )\n",
    "    print('PADDING 완료!')    \n",
    "    return preprocessed_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-boost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92197 개의 데이터 존재 확인!\n",
      "      5000 번째 데이터 처리 완료!\n",
      "      10000 번째 데이터 처리 완료!\n",
      "      15000 번째 데이터 처리 완료!\n",
      "      20000 번째 데이터 처리 완료!\n",
      "      25000 번째 데이터 처리 완료!\n",
      "      30000 번째 데이터 처리 완료!\n",
      "      35000 번째 데이터 처리 완료!\n",
      "      40000 번째 데이터 처리 완료!\n"
     ]
    }
   ],
   "source": [
    "IGNORED_WORDS = ['변경','요청']\n",
    "MAX_SENTENCE_LEN = 200\n",
    "preprocessed_X = preprocess_sentence(X, w2v_model, MAX_SENTENCE_LEN, IGNORED_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test 분리\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(preprocessed_X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배열을 numpy 로 변경\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test  = np.array(X_test)\n",
    "y_test  = np.array(y_test)\n",
    "\n",
    "print( len(X_train) )\n",
    "print( len(X_test) )\n",
    "print( len(y_train) )\n",
    "print( len(y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘 됐나?\n",
    "index = 800\n",
    "print( [w2v_model.index2word[i] for i in X_train[index]] )\n",
    "print( X_train[index] )\n",
    "print( y_train[index] )\n",
    "print( label_encoder.inverse_transform([y_train[index]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention class. (ratsgo 샘플 약간 변형)\n",
    "class Attention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        # (batch, )\n",
    "        self.w1 = Dense(units, activation='tanh')\n",
    "        self.w2 = Dense(1)    \n",
    "        self.softmax_ = Softmax(axis=1)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # (batch, seq, embedding_dim*2) -> # (batch, seq, dec_units)\n",
    "        x = self.w1(x)\n",
    "        # (batch, seq, dec_units) -> # (batch, seq, 1)\n",
    "        score = self.softmax_( self.w2(x) )\n",
    "\n",
    "        return tf.squeeze( tf.matmul(tf.transpose(x, perm=[0, 2, 1]), score ), axis=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차원 테스트\n",
    "Attention(128)( np.zeros([64, 200, 128*2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL 모델. \n",
    "class SORClassifier(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, \n",
    "                 batch_size, embedding_weights, apply_attention, train_embedding_layer, dropout, classes):\n",
    "        super(SORClassifier, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            weights=[embedding_weights])\n",
    "        self.lstm = Bidirectional( LSTM(self.dec_units, return_sequences=apply_attention) )\n",
    "        self.fc1 = Dense(128, activation='relu')\n",
    "        self.fc2 = Dense(classes, activation='softmax')\n",
    "        self.do1 = Dropout(dropout)\n",
    "        self.do2 = Dropout(dropout)\n",
    "        \n",
    "        self.attention = Attention(self.dec_units)\n",
    "        self.embedding.trainable = train_embedding_layer\n",
    "        self.apply_attention = apply_attention\n",
    "        \n",
    "    # 단어id 벡터 -> embedding layer -> dropout -> bilstm -> (opt)attention -> fc -> droupout -> fc(softmax)\n",
    "    def call(self, x):\n",
    "        # (batch, seq) -> (batch, seq, embedding_dim)        \n",
    "        x = self.embedding(x)\n",
    "        x = self.do1(x)\n",
    "        # (batch, seq, embedding_dim) -> (batch, seq, embedding_dim*2)        \n",
    "        x = self.lstm(x)\n",
    "        \n",
    "        # (batch, seq, embedding_dim*2) -> (batch, embedding_dim)        \n",
    "        if self.apply_attention:\n",
    "            x = self.attention(x)\n",
    "        \n",
    "        # (batch, embedding_dim) -> (batch, 128)    \n",
    "        x = self.fc1(x)\n",
    "        x = self.do2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(vocab_size, embedding_dim, dec_units, epochs, batch_size, \n",
    "       weights, apply_attention, train_embedding_layer, dropout, classes):\n",
    "    model = SORClassifier(\n",
    "        vocab_size, \n",
    "        embedding_dim, \n",
    "        dec_units, \n",
    "        batch_size,\n",
    "        weights,\n",
    "        apply_attention,\n",
    "        train_embedding_layer,\n",
    "        dropout,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    \n",
    "    test_score = model.evaluate(X_test, y_test, verbose=2)\n",
    "    \n",
    "    plot_hist(history)\n",
    "    \n",
    "    return history, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'apply_attention': [True],\n",
    "    'train_embedding_layer': [False],\n",
    "    'dropout': [0.3],\n",
    "    'weights': ['weight']#, 'norm_weight']\n",
    "}\n",
    "\n",
    "histories = dict()\n",
    "test_scores = dict()\n",
    "\n",
    "DEC_UNITS = 128\n",
    "EPOCHS=10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for a in hyper_params['apply_attention']:\n",
    "    for te in hyper_params['train_embedding_layer']:\n",
    "        for do in hyper_params['dropout']:\n",
    "            for w in hyper_params['weights']:\n",
    "                vocab_size, embedding_dim = w2v_model.weight.shape\n",
    "                history, test_score = \\\n",
    "                    train_and_evaluate(vocab_size, \n",
    "                                       embedding_dim,\n",
    "                                       DEC_UNITS,\n",
    "                                       EPOCHS,\n",
    "                                       BATCH_SIZE,\n",
    "                                       w2v_model.weight,\n",
    "                                       a,  # attention 적용할지?\n",
    "                                       te, # embedding layer를 훈련시킬지, freezing시킬지?\n",
    "                                       do, # dropout 비율\n",
    "                                       len(label_encoder.classes_)) # class 개수\n",
    "                model_name = f'{a}-{te}-{do}-{w}-{i}'\n",
    "                histories[model_name] = history\n",
    "                test_scores[model_name] = test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
